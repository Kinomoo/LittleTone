# ai_service.py
# é€™è£¡è² è²¬è·Ÿ OpenAI é€£ç·šï¼Œä¸¦è™•ç†åœ¨åœ°åŒ–çŸ¥è­˜åº«çš„æª¢ç´¢

from openai import OpenAI
import os
import json
from dotenv import load_dotenv
import prompts # åŒ¯å…¥ prompts.py

# åˆå§‹åŒ–
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# --- æ–°å¢ï¼šåœ¨åœ°åŒ–å­—å…¸è™•ç†é‚è¼¯ ---

def load_localization_data():
    """å¾ data è³‡æ–™å¤¾è¼‰å…¥åœ¨åœ°åŒ–è¡“èª JSON"""
    try:
        # ä½¿ç”¨ç›¸å°è·¯å¾‘ç¢ºä¿åœ¨ä¸åŒç’°å¢ƒä¸‹éƒ½èƒ½è®€åˆ°
        json_path = os.path.join(os.path.dirname(__file__), 'data', 'localization_dictionary.json')
        with open(json_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"ç„¡æ³•è¼‰å…¥å­—å…¸: {e}")
        return []

def get_relevant_context(user_text):
    """
    æ¯”å°ä½¿ç”¨è€…è¼¸å…¥çš„æ–‡å­—ï¼Œæ‰¾å‡º JSON ä¸­å°æ‡‰çš„è¡“èªè³‡è¨Šã€‚
    é€™æ˜¯ä¸€å€‹ç°¡å–®çš„ RAG æª¢ç´¢é‚è¼¯ï¼ˆKeyword-based Retrievalï¼‰ã€‚
    """
    dictionary = load_localization_data()
    relevant_context = ""
    
    for item in dictionary:
        # å¦‚æœä½¿ç”¨è€…è¨Šæ¯åŒ…å«è¡“èª (ä¾‹å¦‚ï¼šç©©èŠã€å¾ˆè§£)
        if item['term'] in user_text:
            relevant_context += (
                f"\n[åµæ¸¬åˆ°åœ¨åœ°åŒ–è¡“èªï¼š{item['term']}]\n"
                f"æ­£ç¢ºå®šç¾©ï¼š{item['definition']}\n"
                f"èªæ°£å»ºè­°ï¼š{item['tone_advice']}\n"
                f"æ¨è–¦å›è¦†ç¤ºç¯„ï¼š{item['suggestions'][0]}\n"
            )
    
    return relevant_context

# --- æ ¸å¿ƒé‚è¼¯ä¿®æ”¹ ---

def get_emotion_response(messages_history):
    """
    è™•ç† LittleTone çš„æ ¸å¿ƒé‚è¼¯ï¼š
    æ¥æ”¶åŒ…å«å°è©±æ­·å²çš„åˆ—è¡¨ï¼Œå›å‚³åŒ…å« reply, options, key_change, analysis, tip çš„ JSON å­—å…¸ã€‚
    """
    try:
        # 1. å–å¾—ä½¿ç”¨è€…æœ€å¾Œä¸€å¥è©±ï¼Œç”¨ä¾†æª¢ç´¢çŸ¥è­˜åº«
        last_user_message = ""
        for msg in reversed(messages_history):
            if msg["role"] == "user":
                last_user_message = msg["content"]
                break
        
        # 2. ç²å–ç›¸é—œèƒŒæ™¯çŸ¥è­˜
        context = get_relevant_context(last_user_message)
        
        # 3. çµ„åˆç³»çµ±æŒ‡ä»¤
        # æˆ‘å€‘å°‡ context å‚³éçµ¦ prompts æ¨¡çµ„ï¼ˆä¸‹ä¸€æ®µæˆ‘å€‘æœƒå»ä¿®æ”¹ prompts.py ä¾†æ¥æ”¶é€™å€‹è®Šæ•¸ï¼‰
        system_content = prompts.get_formatted_prompt(context)

        full_messages = [
            {"role": "system", "content": system_content}
        ] + messages_history

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            response_format={"type": "json_object"},
            messages=full_messages,
            temperature=0.75, 
            presence_penalty=0.6,
            max_tokens=800
        )
        
        return json.loads(response.choices[0].message.content)
        
    except Exception as e:
        print(f"Error in ai_service: {e}")
        return {
            "reply": "ä¸å¥½æ„æ€ï¼Œæˆ‘å‰›æ‰ç¨å¾®åˆ†ç¥äº†ï¼Œèƒ½è«‹æ‚¨å†èªªä¸€æ¬¡å‰›æ‰ç™¼ç”Ÿçš„ç‹€æ³å—ï¼ŸğŸŒ±", 
            "options": [
                {"title": "é‡æ–°æè¿°", "content": "ï¼ˆè«‹é‡æ–°è¼¸å…¥æ‚¨æƒ³è™•ç†çš„è¨Šæ¯ï¼‰"}
            ], 
            "key_change": "ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿï¼šç›®å‰é€£ç·šç¨å¾®æœ‰é»ä¸ç©©å®š", 
            "analysis": "ç³»çµ±æš«æ™‚ç„¡æ³•è™•ç†æ‚¨çš„è¨Šæ¯ã€‚", 
            "tip": "å†éº»ç…©æ‚¨é‡æ–°ç™¼é€ä¸€æ¬¡è©¦è©¦çœ‹ï¼"
        }