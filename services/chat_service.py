import os
import json
import re
from openai import AsyncOpenAI
from .prompts import get_formatted_prompt
from .rag_service import retrieve_social_knowledge
from .image_service import ImageService

# åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class ChatService:
    @staticmethod
    async def get_little_tone_final_response(user_text, image_base64=None, history=None):
        """
        æ ¸å¿ƒé‚è¼¯ï¼šæ•´åˆ RAG æª¢ç´¢ã€æ­·å²ç´€éŒ„ã€åœ–ç‰‡å£“ç¸®èˆ‡ OpenAI ç”Ÿæˆã€‚
        """
        try:
            # 1. åŸ·è¡Œ RAG æª¢ç´¢ (ç¶­æŒä½ çš„å…§éƒ¨è‡ªå‹•å‘¼å«é‚è¼¯)
            context_info = retrieve_social_knowledge(user_text)
            
            # 2. ç”¢ç”Ÿæˆå«æœ‰åœ¨åœ°åŒ–çŸ¥è­˜çš„ System Prompt
            system_prompt = get_formatted_prompt(context_info)
            messages = [{"role": "system", "content": system_prompt}]
            
            # 3. æ³¨å…¥å°è©±ç´€éŒ„ (æ¡ç´çµ„å“¡çš„ History ç®¡ç†ï¼Œç¶­æŒé€£è²«æ€§)
            if history and isinstance(history, list):
                # å–æœ€è¿‘ 6 å‰‡è¨Šæ¯ä»¥ç¶­æŒä¸Šä¸‹æ–‡è¨˜æ†¶
                messages.extend(history[-6:])
            
            # 4. æ§‹å»ºç•¶å‰çš„ä½¿ç”¨è€…è¼¸å…¥å…§å®¹
            user_content = []
            if user_text:
                user_content.append({"type": "text", "text": user_text})
            elif image_base64:
                # è‹¥åƒ…æœ‰åœ–ç‰‡ï¼Œçµ¦äºˆé è¨­æŒ‡ä»¤
                user_content.append({"type": "text", "text": "è«‹å¹«æˆ‘åˆ†æé€™å¼µæˆªåœ–çš„ç¤¾äº¤è„ˆçµ¡ã€‚"})
                
            # 5. è™•ç†åœ–ç‰‡å£“ç¸® (ç¶­æŒä½ çš„æ•ˆèƒ½å„ªåŒ–é‚è¼¯)
            if image_base64:
                # å‘¼å« ImageService é€²è¡ŒäºŒæ¬¡å£“ç¸®ï¼Œç¯€çœæˆæœ¬
                compressed_image = ImageService.process_and_compress_base64(image_base64)
                user_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{compressed_image}",
                        "detail": "high" # ç¢ºä¿ AI èƒ½çœ‹æ¸…æˆªåœ–æ–‡å­—
                    }
                })

            messages.append({"role": "user", "content": user_content})

            # 6. å‘¼å« OpenAI
            response = await client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                response_format={"type": "json_object"}, # ç¢ºä¿è¼¸å‡ºæ ¼å¼
                temperature=0.4 # å–ä¸­é–“å€¼ï¼Œå…¼é¡§ç©©å®šèˆ‡å‰µæ„
            )

            # 7. ä½¿ç”¨çµ„å“¡çš„ JSON æ¸…ç†æ©Ÿåˆ¶è§£æçµæœ
            return ChatService._parse_json_content(response.choices[0].message.content)

        except Exception as e:
            print(f"[ChatService Error]: {str(e)}")
            return ChatService._get_error_response()

    @staticmethod
    def _parse_json_content(content: str) -> dict:
        """
        è§£æä¸¦æ¸…ç† AI å›å‚³çš„ JSONï¼Œç§»é™¤å¯èƒ½å¹²æ“¾çš„æ¨™ç±¤ã€‚
        """
        try:
            # æ¡ç´çµ„å“¡çš„æ­£è¦è¡¨é”å¼æ¸…ç†æ©Ÿåˆ¶
            clean_str = re.sub(r"```json\n?|\n?```", "", content).strip()
            return json.loads(clean_str)
        except Exception:
            return ChatService._get_error_response()

    @staticmethod
    def _get_error_response() -> dict:
        """
        ç³»çµ±éŒ¯èª¤æ™‚çš„é è¨­å›å‚³ï¼ŒKey å€¼å·²ä¿®æ­£ç‚ºç¬¦åˆä½ çš„å‰ç«¯æ ¼å¼ã€‚
        """
        return {
            "reply": "ä¸å¥½æ„æ€ï¼Œæˆ‘å‰›å‰›ç¨å¾®èµ°ç¥äº†...å¯ä»¥è«‹ä½ å†èªªä¸€æ¬¡å—ï¼ŸğŸŒ±",
            "key_change": "ğŸ’¡ æ ¸å¿ƒæ´å¯Ÿï¼šä¼ºæœå™¨é€£ç·šæš«æ™‚ä¸ç©©ã€‚",
            "suggested_scenarios": [], # ç¶­æŒä½ çš„æ¬„ä½åç¨±
            "analysis": "Error",
            "tip": "å»ºè­°æª¢æŸ¥ API Key é¤˜é¡æˆ–ç¶²è·¯é€£ç·šã€‚"
        }

# ç¢ºä¿ app.py çš„èª¿ç”¨æ¥å£æ­£å¸¸é‹ä½œ
get_little_tone_final_response = ChatService.get_little_tone_final_response